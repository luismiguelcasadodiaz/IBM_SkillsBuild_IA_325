{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNtjk4lrQ+kINz8czGq5XD9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luismiguelcasadodiaz/IBM_SkillsBuild_IA_325/blob/main/IA_325_py_cod_ex_32_s.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest\n",
        "El objetivo es implementar una función que:\n",
        "\n",
        "+ 1.- **Entrene** un modelo Random Forest (RandomForestClassifier).\n",
        "+ 2.-Haga **predicciones** en datos de prueba.\n",
        "+ 3.-**Evalúe** el rendimiento del modelo con:\n",
        "  + **Precisión** (accuracy_score)\n",
        "  + **Matriz de confusión** (confusion_matrix)\n",
        "  + **Reporte de clasificación** (classification_report)\n",
        "+ 4.-**Devuelva los resultados en un diccionario**.\n",
        "+ 5.-**Supervise la implementación con pruebas unitarias** (unittest).\n",
        "\n",
        "\n",
        "\n",
        "## Instrucciones\n",
        "\n",
        "### 1.- Implementa una función llamada entrenar_y_evaluar_random_forest(X_train, y_train, X_test, y_test) que:\n",
        "\n",
        "  + **Entrene** un RandomForestClassifier(n_estimators=100, random_state=42).\n",
        "  + **Prediga** los valores de X_test.\n",
        "  + **Calcule** las métricas de evaluación mencionadas.\n",
        "  + **Devuelva** un diccionario con:\n",
        "\n",
        "   + \"predicciones\": Array de predicciones del modelo.\n",
        "   +  \"accuracy\": Precisión del modelo en los datos de prueba.\n",
        "   +  \"matriz_confusion\": Matriz de confusión.\n",
        "   +  \"reporte\": Reporte de clasificación.\n",
        "\n",
        "### 2.- Usa el dataset de vinos (wine dataset) de sklearn.datasets.\n",
        "\n",
        "###3.- Asegúrate de que el modelo tenga al menos 90% de precisión en los datos de prueba.\n",
        "\n",
        "\n",
        "\n",
        "## Ejemplo de Uso\n",
        "\n",
        "El siguiente código debería ejecutarse correctamente una vez que implementes la función:\n",
        "```python\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Cargar el dataset de vinos\n",
        "wine = load_wine()\n",
        "X = wine.data  # Características\n",
        "y = wine.target  # Clases de vinos\n",
        "\n",
        "# Dividir en conjunto de entrenamiento (80%) y prueba (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Importar la función implementada\n",
        "from solution import entrenar_y_evaluar_random_forest\n",
        "\n",
        "# Llamar a la función y obtener las métricas\n",
        "resultados = entrenar_y_evaluar_random_forest(X_train, y_train, X_test, y_test)\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(\"Precisión del modelo:\", resultados[\"accuracy\"])\n",
        "print(\"Matriz de Confusión:\\n\", resultados[\"matriz_confusion\"])\n",
        "print(\"Reporte de Clasificación:\\n\", resultados[\"reporte\"])\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "## Salida esperada (aproximada)\n",
        "```python\n",
        "Precisión del modelo: 1.0\n",
        "Matriz de Confusión:\n",
        " [[14  0  0]\n",
        " [ 0 14  0]\n",
        " [ 0  0  8]]\n",
        "Reporte de Clasificación:\n",
        "               precision    recall  f1-score   support\n",
        "\n",
        "     Clase 0       1.00      1.00      1.00        14\n",
        "     Clase 1       1.00      1.00      1.00        14\n",
        "     Clase 2       1.00      1.00      1.00         8\n",
        "\n",
        "    accuracy                           1.00        36\n",
        "   macro avg       1.00      1.00      1.00        36\n",
        "weighted avg       1.00      1.00      1.00        36\n",
        "```\n"
      ],
      "metadata": {
        "id": "eXxWAucG9glG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importación de librerías"
      ],
      "metadata": {
        "id": "6G1_jdi8aus-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, \\\n",
        "classification_report\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import unittest"
      ],
      "metadata": {
        "id": "fh74OJVMay1N"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definición de la función solicitada"
      ],
      "metadata": {
        "id": "f_LxNpjFaXAR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bHUQcElE9UQh"
      },
      "outputs": [],
      "source": [
        "def entrenar_y_evaluar_random_forest(X_train, y_train, X_test, y_test):\n",
        "  \"\"\"\n",
        "  Entrena un modelo Random Forest y evalúa su rendimiento.\n",
        "\n",
        "  Args:\n",
        "    X_train: Datos de entrenamiento.\n",
        "    y_train: Etiquetas de entrenamiento.\n",
        "    X_test: Datos de prueba.\n",
        "    y_test: Etiquetas de prueba.\n",
        "\n",
        "  Returns:\n",
        "    Un diccionario con las predicciones, precisión, matriz de confusión\n",
        "    y reporte de clasificación.\n",
        "  \"\"\"\n",
        "  # Verificar que los argumentos no sean nulos.\n",
        "  if X_train is None or y_train is None or X_test is None or y_test is None:\n",
        "    raise ValueError(\"Los argumentos no pueden ser nulos.\")\n",
        "  # Verificar que los tamaños de los conjuntos de entrenamiento y prueba coincidan.\n",
        "  if X_train.shape[0] != y_train.shape[0] or X_test.shape[0] != y_test.shape[0]:\n",
        "    raise ValueError(\"Los tamaños de X_train, y_train, X_test y y_test deben ser iguales.\")\n",
        "  # Verificar que el número de características sea el mismo.\n",
        "  if X_train.shape[1] != X_test.shape[1]:\n",
        "    raise ValueError(\"El número de características en X_train y X_test debe ser el mismo.\")\n",
        "  # Verificar que las etiquetas sean unidimensionales.\n",
        "  if y_train.ndim != 1 or y_test.ndim != 1:\n",
        "    raise ValueError(\"Las etiquetas deben ser unidimensionales.\")\n",
        "\n",
        "  # Inicializar el modelo Random Forest.\n",
        "  rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "  # Entrenar el modelo.\n",
        "  rfc.fit(X_train, y_train)\n",
        "\n",
        "  # Realizar predicciones en los datos de prueba.\n",
        "  y_predid = rfc.predict(X_test)\n",
        "\n",
        "  # Calcular métricas de evaluación.\n",
        "  accuracy = accuracy_score(y_test, y_predid)\n",
        "  matriz_confusion = confusion_matrix(y_test, y_predid)\n",
        "  reporte = classification_report(y_test, y_predid)\n",
        "\n",
        "  # Devolver los resultados en un diccionario.\n",
        "  return {\"predicciones\": y_predid, \\\n",
        "          \"accuracy\": accuracy, \\\n",
        "          \"matriz_confusion\": matriz_confusion, \\\n",
        "          \"reporte\": reporte}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definición de la batería de tests"
      ],
      "metadata": {
        "id": "sAPxpxZ2acok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestRandomForestEvaluation(unittest.TestCase):\n",
        "\n",
        "    def setUp(self):\n",
        "        \"\"\"Set up a synthetic dataset for testing.\"\"\"\n",
        "        wine = load_wine()\n",
        "        X = wine.data  # Características\n",
        "        y = wine.target\n",
        "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "    def test_valid_input(self):\n",
        "        \"\"\"Test with valid input data.\"\"\"\n",
        "        results = entrenar_y_evaluar_random_forest(self.X_train, self.y_train, self.X_test, self.y_test)\n",
        "        self.assertIsInstance(results, dict)\n",
        "        self.assertIn(\"predicciones\", results)\n",
        "        self.assertIn(\"accuracy\", results)\n",
        "        self.assertIn(\"matriz_confusion\", results)\n",
        "        self.assertIn(\"reporte\", results)\n",
        "        self.assertIsInstance(results[\"accuracy\"], float)\n",
        "        self.assertIsInstance(results[\"matriz_confusion\"], np.ndarray)\n",
        "        self.assertIsInstance(results[\"reporte\"], str)\n",
        "\n",
        "    def test_none_input(self):\n",
        "        \"\"\"Test with None values as input.\"\"\"\n",
        "        with self.assertRaises(ValueError):\n",
        "            entrenar_y_evaluar_random_forest(None, self.y_train, self.X_test, self.y_test)\n",
        "        with self.assertRaises(ValueError):\n",
        "            entrenar_y_evaluar_random_forest(self.X_train, None, self.X_test, self.y_test)\n",
        "        with self.assertRaises(ValueError):\n",
        "            entrenar_y_evaluar_random_forest(self.X_train, self.y_train, None, self.y_test)\n",
        "        with self.assertRaises(ValueError):\n",
        "            entrenar_y_evaluar_random_forest(self.X_train, self.y_train, self.X_test, None)\n",
        "\n",
        "    def test_mismatched_samples(self):\n",
        "        \"\"\"Test with mismatched number of samples between X and y.\"\"\"\n",
        "        with self.assertRaises(ValueError):\n",
        "            entrenar_y_evaluar_random_forest(self.X_train[:-1], self.y_train, self.X_test, self.y_test)\n",
        "        with self.assertRaises(ValueError):\n",
        "            entrenar_y_evaluar_random_forest(self.X_train, self.y_train[:-1], self.X_test, self.y_test)\n",
        "\n",
        "    def test_mismatched_features(self):\n",
        "        \"\"\"Test with mismatched number of features between train and test.\"\"\"\n",
        "        with self.assertRaises(ValueError):\n",
        "            entrenar_y_evaluar_random_forest(self.X_train[:, :-1], self.y_train, self.X_test, self.y_test)\n",
        "\n",
        "    def test_multidimensional_labels(self):\n",
        "        \"\"\"Test with multidimensional label arrays.\"\"\"\n",
        "        with self.assertRaises(ValueError):\n",
        "            entrenar_y_evaluar_random_forest(self.X_train, np.vstack([self.y_train, self.y_train]).T, self.X_test, self.y_test)\n",
        "        with self.assertRaises(ValueError):\n",
        "            entrenar_y_evaluar_random_forest(self.X_train, self.y_train, self.X_test, np.vstack([self.y_test, self.y_test]).T)\n",
        "\n",
        "    def test_accuracy_threshold(self):\n",
        "        \"\"\"Test if accuracy meets the threshold (requires a dataset where this is likely).\"\"\"\n",
        "        # This test might fail with the synthetic data if the model performs poorly.\n",
        "        # For the wine dataset, it should pass as per the problem description.\n",
        "        # For this test to be reliable, you might need a specific dataset\n",
        "        # where the model is guaranteed to have high accuracy.\n",
        "        from sklearn.datasets import load_wine\n",
        "        wine = load_wine()\n",
        "        X = wine.data\n",
        "        y = wine.target\n",
        "        X_train_wine, X_test_wine, y_train_wine, y_test_wine = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        results = entrenar_y_evaluar_random_forest(X_train_wine, y_train_wine, X_test_wine, y_test_wine)\n",
        "        self.assertGreaterEqual(results[\"accuracy\"], 0.9)"
      ],
      "metadata": {
        "id": "l1KUFxakaGBA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ejecución de los test"
      ],
      "metadata": {
        "id": "_VUobTrcaja7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unittest.main(argv=['first-arg-is-ignored'], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffTB2Jq0anZD",
        "outputId": "ae7a3875-71fe-4506-b72c-4e57eea88614"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "......\n",
            "----------------------------------------------------------------------\n",
            "Ran 6 tests in 0.659s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x780cb6ec5b10>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo de uso"
      ],
      "metadata": {
        "id": "9Fa7AC2lbiZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el dataset de vinos\n",
        "wine = load_wine()\n",
        "X = wine.data  # Características\n",
        "y = wine.target  # Clases de vinos\n",
        "\n",
        "# Dividir en conjunto de entrenamiento (80%) y prueba (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Importar la función implementada\n",
        "#from solution import entrenar_y_evaluar_random_forest\n",
        "\n",
        "# Llamar a la función y obtener las métricas\n",
        "resultados = entrenar_y_evaluar_random_forest(X_train, y_train, X_test, y_test)\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(\"Precisión del modelo:\", resultados[\"accuracy\"])\n",
        "print(\"Matriz de Confusión:\\n\", resultados[\"matriz_confusion\"])\n",
        "print(\"Reporte de Clasificación:\\n\", resultados[\"reporte\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhNvT7ItYLzW",
        "outputId": "3657b6d1-40ec-430f-e85e-2ff83b16f5c5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precisión del modelo: 1.0\n",
            "Matriz de Confusión:\n",
            " [[14  0  0]\n",
            " [ 0 14  0]\n",
            " [ 0  0  8]]\n",
            "Reporte de Clasificación:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        14\n",
            "           1       1.00      1.00      1.00        14\n",
            "           2       1.00      1.00      1.00         8\n",
            "\n",
            "    accuracy                           1.00        36\n",
            "   macro avg       1.00      1.00      1.00        36\n",
            "weighted avg       1.00      1.00      1.00        36\n",
            "\n"
          ]
        }
      ]
    }
  ]
}